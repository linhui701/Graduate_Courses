\documentclass[12pt,thmsa]{article}

%maths
\usepackage{amsmath}   % \sideset
\usepackage{amsthm}    % for proof
\usepackage{amsfonts}  % for \mathbb
\usepackage{mathrsfs}  % for Ralph Smith's Formal Script Font
\usepackage[mathscr]{euscript} %redefine the \mathcal command to use Euler script
\usepackage{amssymb}   % \varnothing, \bigstar, \blacksquare, \clubsuit, \blacktriangleright, \diamondsuit, \spadesuit, \dagger, \checkmark

%algorithms
\usepackage{algorithm} % http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx

%tables
\usepackage{booktabs}  % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{multirow}
\usepackage{multicol}
\usepackage{tabularx}
\usepackage[table]{xcolor} % For \cellcolor
\usepackage[export]{adjustbox}

%figures
\usepackage{graphicx}  % Allows including images
\usepackage{float}     % Force figure placement in text with [H]

%tikzpicture
\usepackage{tikz}
\usepackage{scalerel}
\usepackage{pict2e}
\usepackage{tkz-euclide}
\usetikzlibrary{matrix}
\usetikzlibrary{shapes, positioning}
\usetikzlibrary{calc}
\usetikzlibrary{patterns, arrows.meta}
\usetikzlibrary{shadows}
\usetikzlibrary{external}

%pgfplots
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepgfplotslibrary{statistics}
\usepgfplotslibrary{fillbetween}

%colors
\usepackage{color}     % color

%other
\usepackage{cancel}
\usepackage{enumitem}
\setlist[itemize]{leftmargin=*} % global option, remove the indentation for a specific list
\usepackage{textcase}  % \MakeTextUppercase
\renewcommand{\qedsymbol}{$\blacksquare$} % change the QED symbol to a filled square
\usepackage{hyperref}

%layout
\usepackage{geometry}

\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	right=20mm,
	top=20mm,
}

% Linhui added for newly defined color
\definecolor{forestgreen}{RGB}{34,139,34}

% Linhui added for Expectation and Variance
\newcommand{\Exp}{{\mathbb E}\! }
\newcommand{\Var}{\mbox{Var}\! }

% Linhui added for rename the command for empty set.
\let\oldemptyset\emptyset
\let\emptyset\varnothing

% Linhui added for empty box.
\newcommand{\emptybox}[2][0.6em]{% 
	\fbox{\rule{0pt}{#1}\hspace{#2}}%
}

% Linhui added for vertically centered boxed content
\newcommand{\vcenteredbox}[1]{%
	\begingroup
	\setbox0=\hbox{#1}%
	\parbox{\wd0}{\box0}%
	\endgroup
}

%------------------------------------------------------%
\makeatletter
\def\maketitle{%
	\par
	\hrule height 1.5pt\vspace{1ex}
	\par\noindent
	
	\begin{minipage}{0.5\textwidth}
		\scshape
		Purdue University \(\cdot\) ece 58000 \\[1ex]
		Optimization Methods \\
		Prof. Żak, Prof. Chong
	\end{minipage}
	\begin{minipage}{0.45\textwidth}
		\raggedleft
		\MakeTextUppercase{{\@title}}\\[0.3ex] % 0.2ex height space between two line
		\textit{\@author}\\[0.2ex]
		\textit{September 15, 2022}
	\end{minipage}
	\par\vspace{1ex}
	\hrule height 1.5pt\vspace{1ex}
	\par
}
\makeatother

\author{Linhui Xie}
\title{Lecture Note 03}
%------------------------------------------------------%

\begin{document}
\maketitle

\setcounter{section}{2}
\section{Taylor Series\medskip}

\setcounter{section}{3}

%%------------------------------------------------------%
%\subsection{Taylor expansion}
%
%\begin{itemize}
%	\item Theorem 05.06.08 Taylor's Theorem. 
%	Assume that a function \(f: \mathbb{R} \rightarrow \mathbb{R}\) is \(m\) times continuously differentiable (i.e., \(f \in \mathcal{C}^{m}\) ) on an interval \([a, b]\). Denote \(h=b-a\). Then
%	\[
%	f(b)=f(a)+\frac{h}{1 !} f^{(1)}(a)+\frac{h^{2}}{2 !} f^{(2)}(a)+\cdots+\frac{h^{m-1}}{(m-1) !} f^{(m-1)}(a)+R_{m}
%	\]
%	(called Taylor's formula) where \(f^{(i)}\) is the ith derivative of \(f\), and
%	\[
%	R_{m}=\frac{h^{m}(1-\theta)^{m-1}}{(m-1) !} f^{(m)}(a+\theta h)=\frac{h^{m}}{m !} f^{(m)}\left(a+\theta^{\prime} h\right)
%	\]
%	with \(\theta, \theta^{\prime} \in(0,1)\).
%	
%	
%	\item Theorem 05.06.09 Mean value theorem
%	If a function \(\boldsymbol{f}: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\) is differentiable on an open set \(\Omega \subset \mathbb{R}^{n}\), then for any pair of points \(\boldsymbol{x}, \boldsymbol{y} \in \Omega\), there exists a matrix \(\boldsymbol{M}\) such that
%	\[
%	\boldsymbol{f}(\boldsymbol{x})-\boldsymbol{f}(\boldsymbol{y})
%	=\boldsymbol{M}(\boldsymbol{x}-\boldsymbol{y})a \boldsymbol{x}+(1-\alpha) \boldsymbol{y}, \alpha \in[0,1]\}.
%	\]
%
%\end{itemize}
%
%Example:
%
%Compute the linear \(\ell\left(x_{1}, x_{2}\right)\) and quadratic \(q\left(x_{1}, x_{2}\right)\) approximation of the function \( f\left(x_{1}, x_{2}\right)=x_{1}+\frac{3 x_{2}}{x_{1}} \), at the point \( \boldsymbol{x}^{(0)}=\left[\begin{array}{ll}1 & 2\end{array}\right] \).
%Ans: 
%\[ \ell\left(\boldsymbol{x}^{(0)}\right) 
%= \color{blue}{ f(\boldsymbol{x}^{(0)}) 
%	+ D f(\boldsymbol{x}^{(0)}) \left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)} \]
%\[ \begin{aligned} 
%	D f(\boldsymbol{x}) 
%	&=\left[\begin{array}{cc}\frac{\partial f}{\partial x_{1}} & \frac{\partial f}{\partial x_{2}}         
%	\end{array}\right]
%	=\left[\begin{array}{cc}1-\frac{3 x_{2}}{x_{1}^{2}} & \frac{3}{x_{1}} \end{array} \right] \\
%	D f(\boldsymbol{x}^{(0)}) 
%	&= \left[\begin{array}{ll} -5 & 3\end{array}\right] \end{aligned} \]
%\[ \begin{aligned}\ell\left(\boldsymbol{x}^{(0)}\right) 
%	& = f(\boldsymbol{x}^{(0)}) 
%	+ D f(\boldsymbol{x}^{(0)}) \left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right) \\
%	& = \left[1+\frac{3 (2)}{1}\right] 
%	+ \left[\begin{array}{cc}-5&3\end{array}\right]
%	\left[\begin{array}{c}x_{1}-1\\x_{2}-2\end{array}\right] \\
%	& = -5x_{1} + 3x_{2}+6
%\end{aligned} \]
%
%\[ q\left(\boldsymbol{x}^{(0)}\right) 
%= \color{blue}{f(\boldsymbol{x}^{(0)}) 
%	+ D f(\boldsymbol{x}^{(0)}) \left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right) }
%+ \frac{1}{2}\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)^{\top} \mathbf{F} \left(\boldsymbol{x}^{(0)}\right) \cdot\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)\]  \[\mathbf{F}(\boldsymbol{x})=    
%\left[\begin{array}{cc}\frac{6 x_{2}}{x_{1}^{3}} & -\frac{3}{x_{1}^{2}} \\
%	-\frac{3}{x_{1}^{2}} & 0\end{array}\right], \quad     \therefore \mathbf{F}\left(\boldsymbol{x}^{(0)}\right)
%=\left[\begin{array}{cc}12 & -3 \\-3 & 0\end{array}\right]
%\]
%\[ \begin{aligned}
%	q\left(\boldsymbol{x}^{(0)}\right) 
%	& = {\color{blue}{\ell\left(x_{1}, x_{2}\right)}}
%	+ \frac{1}{2} \left[\begin{array}{c}x_{1}-1, x_{2}-2\end{array} \right]
%	\left[\begin{array}{cc}12 & -3 \\-3 & 0\end{array}\right] \cdot\left[\begin{array}{c}x_{1}-1 \\x_{2}-2\end{array}\right] \\
%	& = 6 x_{1}^{2}-3 x_{1} x_{2}-11 x_{1}+6 x_{2}+6 \end{aligned} \]


%------------------------------------------------------%
\subsection{Taylor Examples}
\begin{itemize}
	\item Real-vauled function \(f: \mathbb{R} \rightarrow \mathbb{R}\),
	\[f(x)=f\left(x^{(0)}\right)+\frac{x-x^{(0)}}{1 !} f^{\prime}\left(x^{(0)}\right)+\frac{\left(x-x^{(0)}\right)^{2}}{2 !} f^{\prime \prime}\left(x^{(0)}\right)+R_{3}\].

	\item The \underline{linear approximation} of \(f\) about the point \(\boldsymbol{x}_{0}\), \(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\),
	\[f(\boldsymbol{x})=f\left(\boldsymbol{x}^{(0)}\right)+\left[\quad D f\left(\boldsymbol{x}^{(0)}\right) \quad\right] 
	\left[\begin{aligned} \\ \boldsymbol{x}-\boldsymbol{x}^{(0)} \\  \\\end{aligned}\right]
	+R_{2}.
	\]

	\item The \underline{quadratic approximation} of \(f\) about the point \(\boldsymbol{x}_{0}\), \(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\),
	\begin{align*}
	f(\boldsymbol{x}) =f\left(\boldsymbol{x}^{(0)}\right)
	& + \left[\quad D f\left(\boldsymbol{x}^{(0)}\right) \quad\right] 
	\left[\begin{aligned} \\ \boldsymbol{x}-\boldsymbol{x}^{(0)} \\  \\ \end{aligned}\right] \\
	& + \frac{1}{2 !}\left[\quad
		 \left( \boldsymbol{x}-\boldsymbol{x}^{(0)} \right)^{\top} \quad
		\right] 
		\left[\begin{aligned} &  \\  D^{2} f\left(\boldsymbol{x}^{(0)}\right) & \\ &
		\end{aligned}\right]
		\left[\begin{array}{c} \\ \boldsymbol{x} -\boldsymbol{x}^{(0)} \\ \\ \end{array}\right]
	+R_{3}.
	\end{align*}
	
	\item For \textit{quadratic approximation}, if we assume that \(f \in \mathcal{C}^{3}\), term \(R_{3}\) can be written as
	\begin{align*}
		f(\boldsymbol{x})=f\left(\boldsymbol{x}_{0}\right)
		& + \frac{1}{1 !} D f\left(\boldsymbol{x}_{0}\right)\left(\boldsymbol{x}-\boldsymbol{x}_{0}\right) \\
		& + \frac{1}{2 !}\left(\boldsymbol{x}-\boldsymbol{x}_{0}\right)^{\top} D^{2} f\left(\boldsymbol{x}_{0}\right)\left(\boldsymbol{x}-\boldsymbol{x}_{0}\right)+O\left(\left\|\boldsymbol{x}-\boldsymbol{x}_{0}\right\|^{3}\right).
	\end{align*}

\end{itemize}


%------------------------------------------------------%
\subsection{Directional derivative}
\begin{itemize}
	\item The \underline{directional derivative} is the rate of increase of \(f\) at \(\boldsymbol{x}\) in the direction of \(\boldsymbol{d}\),
	\[
	\frac{\partial f}{\partial \boldsymbol{d}} \triangleq \lim _{\alpha \rightarrow 0} \frac{f(\boldsymbol{x}+\alpha \boldsymbol{d})-f(\boldsymbol{x})}{\alpha}
	=\left.\frac{d}{d \alpha} f(\boldsymbol{x}+\alpha \boldsymbol{d})\right|_{\alpha=0}=\boldsymbol{d}^{\top} \nabla f(\boldsymbol{x}),
	\]where
	\[
	f(\boldsymbol{x}+\alpha \boldsymbol{d})
	=f(\boldsymbol{x})+\alpha \boldsymbol{d}^{\top} \nabla f(\boldsymbol{x})+R_{2}.
	\]
\end{itemize}

\textbf{Short derivation}:

Given \textit{linear approximation} of \(f\) about the point \(\boldsymbol{x}_{0}\), \(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\),
\[f(\boldsymbol{x})=f\left( { \color{forestgreen}{\boldsymbol{x}^{(0)}} } \right)+\left[\quad D f\left( { \color{forestgreen}{\boldsymbol{x}^{(0)}} } \right) \quad\right] 
\left[\begin{aligned} \\ \boldsymbol{x}-{ \color{forestgreen}{\boldsymbol{x}^{(0)}} } \\  \\\end{aligned}\right]
+R_{2}.
\]

Thus,
\[f( \boldsymbol{x}+ { \color{black}{ \alpha \boldsymbol{d}} } )=f\left( { \color{forestgreen}{\boldsymbol{x}} } \right)+\left[\quad D f\left( { \color{forestgreen}{\boldsymbol{x}} } \right) \quad\right] 
\left[\begin{aligned} \\ 
	\boldsymbol{x} + { \color{black}{ \alpha \boldsymbol{d}} } - { \color{forestgreen}{\boldsymbol{x}} } \\  \\ \end{aligned}\right]
+R_{2}.
\]

Substitute back,
\[
\begin{aligned}
	\frac{\partial f}{\partial \boldsymbol{d}} \triangleq \lim _{\alpha \rightarrow 0} \frac{f(\boldsymbol{x}+\alpha \boldsymbol{d})-f(\boldsymbol{x})}{\alpha}
	&= \lim_{\alpha \rightarrow 0 } 
	\frac{ f(\boldsymbol{x}) + \left[ \quad D f \left( \boldsymbol{x} \right) \quad \right]
		\left[ \begin{aligned} \\ \alpha \boldsymbol{d} \\ \\ \end{aligned} \right]
		- f\left( \boldsymbol{x} \right)}
	{\alpha}\\
	&=\left[\quad Df\left(\boldsymbol{x}\right)\quad\right] \left[ \begin{array}{c} \\ \boldsymbol{d}  \\ \\ \end{array} \right]\\
	&=\boldsymbol{d}^{\top} \nabla f(\boldsymbol{x}).
\end{aligned}
\]


%------------------------------------------------------%
\subsection{Taylor series}

\begin{itemize}
	\item[\(\spadesuit\)] \(\mathscr{THEOREM}\)5.8 Taylor's Theorem. 
	Assume that a function \(f: \mathbb{R} \rightarrow \mathbb{R}\) is \(m\) times continuously differentiable (i.e., \(f \in \mathcal{C}^{m}\) ) on an interval \([a, b]\). Denote \(h=b-a\). Then
	\[
	f(b)=f(a)+\frac{h}{1 !} f^{(1)}(a)+\frac{h^{2}}{2 !} f^{(2)}(a)+\cdots+\frac{h^{m-1}}{(m-1) !} f^{(m-1)}(a)+R_{m}
	\]
	where \(m\)-th reminder term can be written with the \(m\)-th derivative of \(f\), \(f^{(m)}\), and
	\[
	R_{m}=\frac{h^{m}(1-\theta)^{m-1}}{(m-1) !} f^{(m)}(a+\theta h)=\frac{h^{m}}{m !} f^{(m)}\left(a+\theta^{\prime} h\right)
	\]
	with \(\theta, \theta^{\prime} \in(0,1)\).
	
	
	\item[\(\spadesuit\)] \(\mathscr{THEOREM}\)5.9 Mean value theorem
	If a function \(\boldsymbol{f}: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}\) is differentiable on an open set \(\Omega \subset \mathbb{R}^{n}\), then for any pair of points \(\boldsymbol{x}, \boldsymbol{y} \in \Omega\), there exists a matrix \(\boldsymbol{M}\) such that
	\[
	\boldsymbol{f}(\boldsymbol{x})-\boldsymbol{f}(\boldsymbol{y})
	=\boldsymbol{M}(\boldsymbol{x}-\boldsymbol{y}).
	\]

\end{itemize}



\newpage
%------------------------------------------------------%
\subsection{Derivation details}

For quadratic approximation, we can think about it in this way,
\[\begin{aligned}
	f( \boldsymbol{x}^{(0)}+{\color{forestgreen}{\alpha} \boldsymbol{d}} ) &= \phi ({\color{forestgreen}{\alpha}}) \\
	&= \phi(0) + \frac{\alpha}{1!}\phi^{'}(0) + \frac{\alpha^{2}}{2!}\phi^{''}(0) + R_3 \end{aligned}
\]

	First order item,
	\[ \frac{d \phi}{d \alpha}=\left[ \quad D f\left( \boldsymbol{x}^{(0)} + \alpha \boldsymbol{d} \right) \quad \right] \left[
	\begin{array}{c} \\ \boldsymbol{d} \\ \\ \end{array}\right],
	\quad \phi^{'}(0)= \left[\quad D f\left(\boldsymbol{x}^{(0)} \right) \quad\right]\left[\begin{aligned} \\ \boldsymbol{d} \\  \\\end{aligned}\right]. \]
	
	Second order term ,
	\[ \begin{aligned} \frac{d^{2} \phi}{d \alpha^{2}}
		& = \frac{d}{d \alpha}\left( \frac{d \phi}{d \alpha} \right) \\
		& = \frac{d}{d \alpha} \left( \left[ \quad D f\left( \boldsymbol{x}^{(0)} + \alpha \boldsymbol{d} \right) \quad \right] 
		\left[\begin{array}{c} \\ \boldsymbol{d} \\ \\ \end{array}\right] 
		\right) \\
		& = \frac{d}{d \alpha} \left( \left[ \qquad \boldsymbol{d}^{\top}  \qquad \right] 
		\left[\begin{array}{c} \\ \nabla f\left( \boldsymbol{x}^{(0)} + \alpha \boldsymbol{d} \right) \\ \\ \end{array}\right] 
		\right) \\
		& = \left[  \qquad \boldsymbol{d}^{\top} \qquad   \right]
		\frac{d}{d \alpha} \left(  
		\left[\begin{array}{c} \\ \nabla f\left( \boldsymbol{x}^{(0)} + \alpha \boldsymbol{d} \right) \\ \\ \end{array}\right] 
		\right) \\
		& = \left[  \qquad \boldsymbol{d}^{\top} \qquad   \right]  
		\left[\begin{array}{c} 
			\vdots \\ 
			\frac{d}{d \alpha} \left( \frac{\partial f}{\partial x_i}\left( \boldsymbol{x}^{(0)} + \alpha \boldsymbol{d} \right) \right) \\ 
			\vdots \\ 
		\end{array}\right]  \\
		& = \left[  \qquad \boldsymbol{d}^{\top} \qquad   \right]  
		\left[\begin{array}{ccc} 
			\vdots & & \vdots \\ 
			\frac{\partial^2 f}{\partial x_1 x_i}\left( \boldsymbol{x}^{(0)} + \alpha \boldsymbol{d} \right) & \dots & \frac{\partial^2 f}{\partial x_n x_i}\left( \boldsymbol{x}^{(0)} + \alpha \boldsymbol{d} \right)   \\ 
			\vdots & & \vdots \\ 
		\end{array}\right] \left[ \begin{array}{c} \\ \boldsymbol{d} \\ \\ \end{array} \right] \\
		& = \left[  \qquad \boldsymbol{d}^{\top} \qquad   \right]  
		\left[\begin{array}{ccc} 
			& &  \\ 
			&  \mathbf{F} \left( \boldsymbol{x}^{(0)} + \alpha \boldsymbol{d} \right) &   \\ 
			& & \\ 
		\end{array}\right] \left[ \begin{array}{c} \\ \boldsymbol{d} \\ \\ \end{array} \right]
	\end{aligned} \]
	In summary,
	\[
	\begin{array}{cll}
		\left.\phi (\alpha)\right|_{ \color{forestgreen}{\alpha}=1 } 
		& = f \left( \boldsymbol{x} \right) & \\
		& = f( \boldsymbol{x}^{(0)} + {\color{forestgreen}{1}} \boldsymbol{d} ) & \\
		& = f( \boldsymbol{x}^{(0)} ) \quad & +  
			\left[ \quad D f(\boldsymbol{x}^{(0)})  \quad \right]
			\left[ \begin{array}{c} \\ \boldsymbol{d} \\ \\ \end{array} \right] \\
		&  &+
			\frac{1}{2} \left[  \qquad \boldsymbol{d}^{\top} \qquad   \right]
			\left[\begin{array}{ccc} 
				& &  \\ 
				&  \mathbf{F} \left( \boldsymbol{x}^{(0)} + {\color{forestgreen}{1}} \boldsymbol{d} \right) &   \\ 
				& & \\ 
			\end{array}\right]
			\left[ \begin{array}{c} \\ \boldsymbol{d} \\ \\ \end{array} \right] + R_3
	\end{array}
	\]

\bigskip

\noindent
[Ref]: Edwin K.P. Chong, Stanislaw H. Żak, ``PART I MATHEMATICAL REVIEW" in ``An introduction to optimization", 4th Edition, John Wiley and Sons, Inc. 2013.

\end{document}
