\documentclass[12pt,thmsa]{article}

%maths
\usepackage{amsmath}   % \sideset
\usepackage{amsthm}    % for proof
\usepackage{amsfonts}  % for \mathbb
\usepackage{mathrsfs}  % for Ralph Smith's Formal Script Font
\usepackage[mathscr]{euscript} %redefine the \mathcal command to use Euler script
\usepackage{amssymb}   % \varnothing, \bigstar, \blacksquare, \clubsuit, \blacktriangleright, \diamondsuit, \spadesuit, \dagger, \checkmark
\usepackage{optidef}   % for optimization definition

%algorithms
\usepackage{algorithm} % http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx

%tables
\usepackage{booktabs}  % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{multirow}
\usepackage{multicol}
\usepackage{tabularx}
\usepackage[table]{xcolor} % For \cellcolor
\usepackage[export]{adjustbox}

%figures
\usepackage{graphicx}  % Allows including images
\usepackage{float}     % Force figure placement in text with [H]

%tikzpicture
\usepackage{tikz}
\usepackage{scalerel}
\usepackage{pict2e}
\usepackage{tkz-euclide}
\usetikzlibrary{matrix}
\usetikzlibrary{shapes, positioning}
\usetikzlibrary{calc}
\usetikzlibrary{patterns, arrows.meta}
\usetikzlibrary{shadows}
\usetikzlibrary{external}

%pgfplots
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usepgfplotslibrary{statistics}
\usepgfplotslibrary{fillbetween}

%colors
\usepackage{color}     % color

%other
\usepackage{cancel}
\usepackage{enumitem}
\setlist[itemize]{leftmargin=*} % global option, remove the indentation for a specific list
\usepackage{textcase}  % \MakeTextUppercase
\renewcommand{\qedsymbol}{$\blacksquare$} % change the QED symbol to a filled square
\usepackage{hyperref}

%layout
\usepackage{geometry}

\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	right=20mm,
	top=20mm,
}

% Linhui added for newly defined color
\definecolor{forestgreen}{RGB}{34,139,34}

% Linhui added for Expectation and Variance
\newcommand{\Exp}{{\mathbb E}\! }
\newcommand{\Var}{\mbox{Var}\! }

% Linhui added for rename the command for empty set.
\let\oldemptyset\emptyset
\let\emptyset\varnothing


%------------------------------------------------------%
\makeatletter
\def\maketitle{%
	\par
	\hrule height 1.5pt\vspace{1ex}
	\par\noindent
	
	\begin{minipage}{0.5\textwidth}
		\scshape
		Purdue University $\cdot$ ece 58000 \\[1ex]
		Optimization Methods \\
		Prof. Żak, Prof. Chong
	\end{minipage}
	\begin{minipage}{0.45\textwidth}
		\raggedleft
		\MakeTextUppercase{{\@title}}\\[0.3ex] % 0.2ex height space between two line
		\textit{\@author}\\[0.2ex]
		\textit{February 1, 2023}
	\end{minipage}
	\par\vspace{1ex}
	\hrule height 1.5pt\vspace{1ex}
	\par
}
\makeatother

\author{Linhui Xie}
\title{Lecture Note 08}
%------------------------------------------------------%

\begin{document}
\maketitle

\setcounter{section}{7}
%------------------------------------------------------%
\section{Gradient Method\medskip}
%------------------------------------------------------%
\setcounter{section}{8}
%------------------------------------------------------%

\begin{itemize}
	\item Gradient algorithm:
	\[
	\boldsymbol{x}^{(k+1)}=\boldsymbol{x}^{(k)}-\alpha_{k} \nabla f\left(\boldsymbol{x}^{(k)}\right) .
	\]
	
	\item Define \( {\color{forestgreen}\boldsymbol{g}^{(k)} }:=\nabla f\left(\boldsymbol{x}^{(k)}\right)\) and  set descent direction to \(\boldsymbol{d}^{(k)}=-\boldsymbol{g}^{(k)}\).

	\item Step size \(\alpha_{k}\) can be chosen in many different ways.
	
	\item For sufficiently small step size, the gradient algorithm has \textit{descent} property.
	
	Define \(\phi(\alpha):=f\left(\boldsymbol{x}^{(k)}-\alpha \boldsymbol{g}^{(k)}\right)\), then \(\phi\) has Taylor expansion:
	\[
	f\left(\boldsymbol{x}^{(k)}-\alpha \boldsymbol{g}^{(k)}\right)=f\left(\boldsymbol{x}^{(k)}\right)-\alpha\left\|\boldsymbol{g}^{(k)}\right\|^2+o(\alpha)
	\]
	For \(\alpha\) sufficiently small, we have
	\[
	f\left(\boldsymbol{x}^{(k)}-\alpha \boldsymbol{g}^{(k)}\right) \leq f\left(\boldsymbol{x}^{(k)}\right)
	\]
	
	\item[\(\blacktriangleright\)] \(\mathscr{PROPOSITION}\) Suppose \( { \color{black}\boldsymbol{g}^{(k)} }=\nabla f\left(\boldsymbol{x}^{(k)}\right) \neq \mathbf{0}\). There exists \(\bar{\alpha}>0\) such that for all \(\alpha_{k} \in(0, \bar{\alpha})\), we have
	\[
		f\left(\boldsymbol{x}^{(k+1)}\right)<f\left(\boldsymbol{x}^{(k)}\right)
	\]

	\item Remark: if \( { \color{black}\boldsymbol{g}^{(k)} }=\mathbf{0}\), the FONC holds. 
	
	Short proof: 
	
	By chain rule, we have
	\[
		\phi^{\prime}(0)= f\left(\boldsymbol{x}^{(k)}\right) = -\left\| { \color{black}\boldsymbol{g}^{(k)} } \right\|^{2}<0 .
	\]

	Gradient is negative thus function value is decreasing. Hence, there exists \(\bar{\alpha}>0\) such that for all \(\alpha_{k} \in(0, \bar{\alpha})\), we have

	\[
		\phi\left(\alpha_{k}\right)<\phi(0) .
	\]

	Rewriting, we obtain
	\[
		f\left(\boldsymbol{x}^{(k+1)}\right)<f\left(\boldsymbol{x}^{(k)}\right).
	\]

	\item A variety of options exist for selecting \(\alpha_{k}\).
	
	\item If \(\alpha_{k}\) too small, an increased number of iterations may be needed to get \underline{optimal solution} \(\boldsymbol{x}^{*}\).
	
	\item If \(\alpha_{k}\) too big, algorithm may lead to an oscillated track (zig-zag) around \(\boldsymbol{x}^{*}\) (overshoot).
	
	\item \underline{General approach} is to set a constant \(\alpha_{k}=\alpha\) for all \(k\).
	
	\item \underline{Steepest approach} change \(\alpha_{k}\) with each successive iteration.
		
\end{itemize}


%------------------------------------------------------%
\subsection{Steepest descent algorithm }
%------------------------------------------------------%
\begin{itemize}
	\item Greedy scheme to pick for \(\alpha_{k}\).
	\[
		\alpha_{k}=\underset{\alpha \geq 0}{\arg \min } f\left(\boldsymbol{x}^{(k)}-\alpha \boldsymbol{g}^{(k)} \right) .
	\]
	\item The steepest descent algorithm has the descent property.
	
	\item[\(\blacktriangleright\)] \(\mathscr{PROPOSITION}\) 8.1 Let \(\left\{\boldsymbol{x}^{(k)}\right\}\) be obtained by steepest descent method,
	\[
		\left( \boldsymbol{x}^{(k+2)}-\boldsymbol{x}^{(k+1)} \right)^{\top} \left( \boldsymbol{x}^{(k+1)}-\boldsymbol{x}^{(k)} \right) = 0.
	\]

	Short Proof:

	Based on definition,
	\[
	\begin{aligned}
		& \boldsymbol{x}^{(k+2)}=\boldsymbol{x}^{(k+1)}-\alpha_{k+1} \boldsymbol{g}^{(k+1)}, \\
		& \boldsymbol{x}^{(k+1)}=\boldsymbol{x}^{(k)}-\alpha_k \boldsymbol{g}^{(k)}.
	\end{aligned}
	\]

	Let \(\phi(\alpha)=f\left(\boldsymbol{x}^{(k)}- \alpha \boldsymbol{g}^{(k)} \right) = f \left( \boldsymbol{x}^{(k+1)} \right) \). Since \(\alpha_k=\arg \min \phi(\alpha)\), by FONC, we have \[\phi^{\prime}\left(\alpha_{k}\right)=0. \]Hence,
	\[
	\phi^{\prime}\left(\alpha_k\right)=\nabla f\left(\boldsymbol{x}^{(k)}-\alpha_k \boldsymbol{g}^{(k)}\right)^{\top} \boldsymbol{g}^{(k)} 
	= \nabla f\left(\boldsymbol{x}^{(k+1)}\right)^{\top} \boldsymbol{g}^{(k)} 
	\overset{\boldsymbol{g}^{(k)}=\nabla f\left(\boldsymbol{x}^{(k)}\right)}{=\joinrel=\joinrel=\joinrel=}
	\boldsymbol{g}^{(k+1)^{\top}} \boldsymbol{g}^{(k)} = 0.
	\]
	
	Therefore,
	\[
	\left(\boldsymbol{x}^{(k+2)}-\boldsymbol{x}^{(k+1)}\right)^{\top}\left(\boldsymbol{x}^{(k+1)}-\boldsymbol{x}^{(k)}\right)=\alpha_{k+1} \alpha_k \boldsymbol{g}^{(k+1)^{\top}} \boldsymbol{g}^{(k)}=0 .
	\]
	
	\item For a prescribed \(\epsilon>0\), terminate the iteration if one of the followings is met:
	\begin{itemize}
		\item[\(\circ\)] \(\left\|\boldsymbol{g}^{(k)}\right\|<\epsilon\);
		\item[\(\circ\)]  \(\left\|\boldsymbol{x}^{(k+1)}-\boldsymbol{x}^{(k)}\right\|<\epsilon\);
		\item[\(\circ\)]  \(\left|f\left(\boldsymbol{x}^{(k+1)}\right)-f\left(\boldsymbol{x}^{(k)}\right)\right|<\epsilon\).
	\end{itemize}

	\item More \underline{preferable choices} using ``relative change", because they are ``scale-free".
	\begin{itemize}
		\item[\(\circ\)]  \(\left|f\left(\boldsymbol{x}^{(k+1)}\right)-f\left(\boldsymbol{x}^{(k)}\right)\right| /\left|f\left(\boldsymbol{x}^{(k)}\right)\right|<\epsilon\);
		\item[\(\circ\)]  \(\left\|\boldsymbol{x}^{(k+1)}-\boldsymbol{x}^{(k)}\right\| /\left\|\boldsymbol{x}^{(k)}\right\|<\epsilon\).
	\end{itemize}
	
\end{itemize}


%------------------------------------------------------%
\subsection{Analysis of optimization algorithms}
%------------------------------------------------------%

\begin{itemize}
	\item \underline{Globally convergent}: starting from any initial point  \(\boldsymbol{x}^{(0)}\), an algorithm that generates sequence \(\boldsymbol{x}^{(k)} \rightarrow \boldsymbol{x}^{*}\), where \(\boldsymbol{x}^{*}\) satisfying the FONC.
	
	\item \underline{Locally convergent}: starting from an initial point \(\boldsymbol{x}^{(0)}\) is sufficiently close to \(\boldsymbol{x}^{*}\), an algorithm generates sequences converges to  \(\boldsymbol{x}^{*}\).
	
	\item \underline{Rate of convergence}: how fast an algorithm converges.
	
\end{itemize}

\bigskip

\noindent
[Ref]: Edwin K.P. Chong, Stanislaw H. Żak, ``PART II UNCONSTRAINED OPTIMIZATION" in ``\href{https://www.amazon.com/Introduction-Optimization-Edwin-K-Chong/dp/1118279018}{An introduction to optimization}", 4th Edition, John Wiley and Sons, Inc. 2013.

\end{document}
